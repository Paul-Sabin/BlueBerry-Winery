{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ww = pd.read_csv('C:\\Asus WebStorage\\psabin@gmail.com\\MySyncFolder\\Data Science Course\\BlueBerry Winery\\winequality-white.csv', sep=';')\n",
    "rw = pd.read_csv('C:\\Asus WebStorage\\psabin@gmail.com\\MySyncFolder\\Data Science Course\\BlueBerry Winery\\winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww['quality_label'] = ww['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "ww['quality_label'] = pd.Categorical(ww['quality_label'],\n",
    "categories=['low', 'medium', 'high'])\n",
    "\n",
    "rw['quality_label'] = rw['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "rw['quality_label'] = pd.Categorical(rw['quality_label'],\n",
    "categories=['low', 'medium', 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "ww['encoded_quality_label'] = le.fit_transform(ww['quality_label'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap 0 for 3 to make the order make sense from low to high\n",
    "ww['encoded_quality_label'].replace(0,3,inplace=True)\n",
    "display(ww.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.drop(['quality_label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>encoded_quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  encoded_quality_label  \n",
       "0      8.8                      2  \n",
       "1      9.5                      2  \n",
       "2     10.1                      2  \n",
       "3      9.9                      2  \n",
       "4      9.9                      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ww.drop(['quality'], axis=1, inplace=True)\n",
    "display(ww.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the features to use as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.045</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.049</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.050</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.058</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.058</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  chlorides  alcohol\n",
       "0            7.0              0.27      0.045      8.8\n",
       "1            6.3              0.30      0.049      9.5\n",
       "2            8.1              0.28      0.050     10.1\n",
       "3            7.2              0.23      0.058      9.9\n",
       "4            7.2              0.23      0.058      9.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ww_select = ww[['fixed acidity', 'volatile acidity', 'chlorides', 'alcohol']]\n",
    "display(ww_select.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create column-vector for quality_label (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: encoded_quality_label, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4898,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_ww_quality = ww.encoded_quality_label\n",
    "display(y_ww_quality.head())\n",
    "display(y_ww_quality.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ww_features_train, ww_features_test, ww_quality_train, ww_quality_test = train_test_split(ww_select,y_ww_quality,test_size=0.2, random_state=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale wine features to even out their impact on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Also try different methods of normalization/standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "ww_features_train_scaled = scaler.fit_transform(ww_features_train)\n",
    "ww_features_test_scaled = scaler.transform(ww_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(ww_features_train_scaled, ww_quality_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = model.predict(ww_features_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.57% accuracy with prediction of low, medium, or high quality of a given wine, based on fixed acidity, volatile acidity, \n",
      "chlorides, and alcohol content.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = ((accuracy_score(ww_quality_test, pred_model)) * 100).round(2)\n",
    "\n",
    "print(f\"{accuracy}% accuracy with prediction of low, medium, or high quality of a given wine, based on fixed acidity, volatile acidity, \\nchlorides, and alcohol content.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Confusion matrix:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[162, 185,   0],\n",
       "       [ 71, 510,   0],\n",
       "       [  5,  47,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "display(\"Confusion matrix:\")\n",
    "display(confusion_matrix(ww_quality_test, pred_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the confusion matrix shows that the model never predicted high quality (third column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function with several ML models at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    log_reg_train_predictions = log_reg.predict(X_train)\n",
    "    log_reg_test_predictions = log_reg.predict(X_test)\n",
    "\n",
    "    gauss = GaussianNB()\n",
    "    gauss.fit(X_train, y_train)\n",
    "    gauss_train_predictions = gauss.predict(X_train)\n",
    "    gauss_test_predictions = gauss.predict(X_test)\n",
    "\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train, y_train)\n",
    "    svc_train_predictions = svc.predict(X_train)\n",
    "    svc_test_predictions = svc.predict(X_test)\n",
    "\n",
    "    svc_lin = SVC(kernel = 'linear', random_state = 0)\n",
    "    svc_lin.fit(X_train, y_train)\n",
    "    svc_lin_train_predictions = svc_lin.predict(X_train)\n",
    "    svc_lin_test_predictions = svc_lin.predict(X_test)\n",
    "\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    tree.fit(X_train, y_train)\n",
    "    tree_train_predictions = tree.predict(X_train)\n",
    "    tree_test_predictions = tree.predict(X_test)\n",
    "\n",
    "    tree_gini = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\n",
    "    tree_gini.fit(X_train, y_train)\n",
    "    tree_gini_train_predictions = tree_gini.predict(X_train)\n",
    "    tree_gini_test_predictions = tree_gini.predict(X_test)\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "    forest.fit(X_train, y_train)\n",
    "    forest_train_predictions = forest.predict(X_train)\n",
    "    forest_test_predictions = forest.predict(X_test)\n",
    "\n",
    "    forest_gini = RandomForestClassifier(n_estimators = 100, criterion = 'gini', random_state = 0)\n",
    "    forest_gini.fit(X_train, y_train)\n",
    "    forest_gini_train_predictions = forest_gini.predict(X_train)\n",
    "    forest_gini_test_predictions = forest_gini.predict(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.001, early_stopping=True, activation='relu', solver='adam', random_state=0)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    mlp_train_predictions = mlp.predict(X_train)\n",
    "    mlp_test_predictions = mlp.predict(X_test)\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_train_predictions = knn.predict(X_train)\n",
    "    knn_test_predictions = knn.predict(X_test)\n",
    "\n",
    "    print('Logistic Regression Training Accuracy:', ((accuracy_score(y_train, log_reg_train_predictions)) * 100).round(2))\n",
    "    print('Logistic Regression Test Accuracy:', ((accuracy_score(y_test, log_reg_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, log_reg_test_predictions))\n",
    "    print('Gaussian Naive Bayes Training Accuracy:', ((accuracy_score(y_train, gauss_train_predictions)) * 100).round(2))\n",
    "    print('Gaussian Naive Bayes Test Accuracy:', ((accuracy_score(y_test, gauss_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, gauss_test_predictions))\n",
    "    print('Support Vector Classification Training Accuracy:', ((accuracy_score(y_train, svc_train_predictions)) * 100).round(2))\n",
    "    print('Support Vector Classification Test Accuracy:', ((accuracy_score(y_test, svc_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, svc_test_predictions))\n",
    "    print('Linear Support Vector Classification Training Accuracy:', ((accuracy_score(y_train, svc_lin_train_predictions)) * 100).round(2))\n",
    "    print('Linear Support Vector Classification Test Accuracy:', ((accuracy_score(y_test, svc_lin_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, svc_lin_test_predictions))\n",
    "    print('Decision Tree Classifier Training Accuracy:', ((accuracy_score(y_train, tree_train_predictions)) * 100).round(2))\n",
    "    print('Decision Tree Classifier Test Accuracy:', ((accuracy_score(y_test, tree_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, tree_test_predictions))\n",
    "    print('Gini Decision Tree Classifier Training Accuracy:', ((accuracy_score(y_train, tree_gini_train_predictions)) * 100).round(2))\n",
    "    print('Gini Decision Tree Classifier Test Accuracy:', ((accuracy_score(y_test, tree_gini_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, tree_gini_test_predictions))\n",
    "    print('Forest Training Accuracy:', ((accuracy_score(y_train, forest_train_predictions)) * 100).round(2))\n",
    "    print('Forest Test Accuracy:', ((accuracy_score(y_test, forest_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, forest_test_predictions))\n",
    "    print('Gini Forest Training Accuracy:', ((accuracy_score(y_train, forest_gini_train_predictions)) * 100).round(2))\n",
    "    print('Gini Forest Test Accuracy:', ((accuracy_score(y_test, forest_gini_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, forest_gini_test_predictions))\n",
    "    print('Neural Network MLP Classifier Training Accuracy:', ((accuracy_score(y_train, mlp_train_predictions)) * 100).round(2))\n",
    "    print('Neural Network MLP Classifier Test Accuracy:', ((accuracy_score(y_test, mlp_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, mlp_test_predictions))\n",
    "    print('K Nearest Neighbors Classifier Training Accuracy:', ((accuracy_score(y_train, knn_train_predictions)) * 100).round(2))\n",
    "    print('K Nearest Neighbors Classifier Test Accuracy:', ((accuracy_score(y_test, knn_test_predictions)) * 100).round(2))\n",
    "    display(confusion_matrix(y_test, knn_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the big function on white wine features (input) quality (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 70.09\n",
      "Logistic Regression Test Accuracy: 71.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[146, 146,   0],\n",
       "       [ 92, 554,   0],\n",
       "       [ 10,  32,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Training Accuracy: 67.71\n",
      "Gaussian Naive Bayes Test Accuracy: 70.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[102, 188,   2],\n",
       "       [ 52, 591,   3],\n",
       "       [  1,  39,   2]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classification Training Accuracy: 72.21\n",
      "Support Vector Classification Test Accuracy: 73.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[150, 142,   0],\n",
       "       [ 78, 568,   0],\n",
       "       [  0,  42,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Classification Training Accuracy: 70.47\n",
      "Linear Support Vector Classification Test Accuracy: 71.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[144, 148,   0],\n",
       "       [ 90, 556,   0],\n",
       "       [  5,  37,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Training Accuracy: 99.92\n",
      "Decision Tree Classifier Test Accuracy: 73.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[184, 103,   5],\n",
       "       [102, 519,  25],\n",
       "       [  4,  17,  21]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Decision Tree Classifier Training Accuracy: 99.92\n",
      "Gini Decision Tree Classifier Test Accuracy: 74.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[194,  97,   1],\n",
       "       [105, 521,  20],\n",
       "       [  4,  20,  18]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Training Accuracy: 99.92\n",
      "Forest Test Accuracy: 79.29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[190, 102,   0],\n",
       "       [ 75, 568,   3],\n",
       "       [  3,  20,  19]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Forest Training Accuracy: 99.92\n",
      "Gini Forest Test Accuracy: 79.59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[192,  99,   1],\n",
       "       [ 75, 569,   2],\n",
       "       [  5,  18,  19]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network MLP Classifier Training Accuracy: 71.44\n",
      "Neural Network MLP Classifier Test Accuracy: 72.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[145, 147,   0],\n",
       "       [ 83, 563,   0],\n",
       "       [  1,  41,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Classifier Training Accuracy: 79.53\n",
      "K Nearest Neighbors Classifier Test Accuracy: 68.57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[155, 137,   0],\n",
       "       [133, 510,   3],\n",
       "       [  6,  29,   7]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models(ww_features_train_scaled, ww_quality_train, ww_features_test_scaled, ww_quality_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
